{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq1wRIavV8k7JeAUacTS62",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kai-wang99/AI_project/blob/main/hftest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2E-W8ERGoVu4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
        "\n",
        "checkpoint = \"gpt2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint,pad_token_id=tokenizer.eos_token_id)\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(text):\n",
        "    cleaned = []\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "    #outputs = model.generate(**inputs, do_sample=True, num_beams=5, max_new_tokens=100, temperature=0.6, no_repeat_ngram_size=2)\n",
        "    outputs = model.generate(**inputs, do_sample=True, num_beams=1, max_new_tokens=100, no_repeat_ngram_size=2)\n",
        "    generated_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    for i in generated_output:\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "Ek0zJZNCmXjv"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"The first computer program that is programmed always says: Hello\"\n",
        "generate(txt)"
      ],
      "metadata": {
        "id": "cg7uKQBrmXVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9d6b67-57e6-4659-f768-faa95f14e7d7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first computer program that is programmed always says: Hello, I'm at a computer party. This is going. Just kidding. I know exactly where you are. And you know precisely what to do. It goes: \"Hey, go and make your move. Put your mouse on the front button of the computer, press the right button, and hit the back button until you get the program you want. Then use the next button to get back to the previous window. Repeat this until everything comes back again.\" The next program is still programmed: Hey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ln7A8Q3P-mNM"
      }
    }
  ]
}